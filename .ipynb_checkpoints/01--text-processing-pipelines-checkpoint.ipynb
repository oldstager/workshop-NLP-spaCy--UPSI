{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88098e6a-261e-4ba4-979d-95c37517761b",
   "metadata": {},
   "source": [
    "# Text Processing Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb0457f1-4792-4cc7-8613-5c85a734a2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "world\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "doc = nlp(\"Hello world!\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeb21a9-5bb1-430d-9a10-6eceb23c8187",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99331543-bf0e-4e7d-a44a-7e163a58b1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial\n",
      "intelligence\n",
      "(\n",
      "AI\n",
      ")\n",
      "is\n",
      "the\n",
      "intelligence\n",
      "of\n",
      "machines\n",
      "or\n",
      "software\n",
      ",\n",
      "\n",
      "\n",
      "as\n",
      "opposed\n",
      "to\n",
      "the\n",
      "intelligence\n",
      "of\n",
      "humans\n",
      "or\n",
      "animals\n",
      ".\n",
      "It\n",
      "is\n",
      "also\n",
      "the\n",
      "field\n",
      "of\n",
      "study\n",
      "in\n",
      "\n",
      "\n",
      "computer\n",
      "science\n",
      "that\n",
      "develops\n",
      "and\n",
      "studies\n",
      "intelligent\n",
      "machines\n",
      ".\n",
      "AI\n",
      "may\n",
      "also\n",
      "refer\n",
      "to\n",
      "\n",
      "\n",
      "the\n",
      "machines\n",
      "themselves\n",
      ".\n",
      "AI\n",
      "technology\n",
      "is\n",
      "widely\n",
      "used\n",
      "throughout\n",
      "industry\n",
      ",\n",
      "government\n",
      "\n",
      "\n",
      "and\n",
      "science\n",
      ".\n",
      "Some\n",
      "high\n",
      "-\n",
      "profile\n",
      "applications\n",
      "are\n",
      ":\n",
      "advanced\n",
      "web\n",
      "search\n",
      "engines\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "\n",
      "\n",
      "Google\n",
      "Search\n",
      ")\n",
      ",\n",
      "recommendation\n",
      "systems\n",
      "(\n",
      "used\n",
      "by\n",
      "YouTube\n",
      ",\n",
      "Amazon\n",
      ",\n",
      "and\n",
      "Netflix\n",
      ")\n",
      ",\n",
      "understanding\n",
      "\n",
      "\n",
      "human\n",
      "speech\n",
      "(\n",
      "such\n",
      "as\n",
      "Siri\n",
      "and\n",
      "Alexa\n",
      ")\n",
      ",\n",
      "self\n",
      "-\n",
      "driving\n",
      "cars\n",
      "(\n",
      "e.g.\n",
      ",\n",
      "Waymo\n",
      ")\n",
      ",\n",
      "generative\n",
      "or\n",
      "\n",
      "\n",
      "creative\n",
      "tools\n",
      "(\n",
      "ChatGPT\n",
      "and\n",
      "AI\n",
      "art\n",
      ")\n",
      ",\n",
      "and\n",
      "competing\n",
      "at\n",
      "the\n",
      "highest\n",
      "level\n",
      "in\n",
      "strategic\n",
      "\n",
      "\n",
      "games\n",
      "(\n",
      "such\n",
      "as\n",
      "chess\n",
      "and\n",
      "Go\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "doc = nlp(\"\"\"Artificial intelligence (AI) is the intelligence of machines or software, \n",
    "as opposed to the intelligence of humans or animals. It is also the field of study in \n",
    "computer science that develops and studies intelligent machines. AI may also refer to \n",
    "the machines themselves. AI technology is widely used throughout industry, government \n",
    "and science. Some high-profile applications are: advanced web search engines (e.g., \n",
    "Google Search), recommendation systems (used by YouTube, Amazon, and Netflix), understanding \n",
    "human speech (such as Siri and Alexa), self-driving cars (e.g., Waymo), generative or \n",
    "creative tools (ChatGPT and AI art), and competing at the highest level in strategic \n",
    "games (such as chess and Go)\"\"\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2af08642-de89-403c-b8aa-c42353d7b92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('$9.4 million', 'MONEY'), ('the prior year', 'DATE'), ('$2.7 million', 'MONEY')]\n",
      "[('twelve billion dollars', 'MONEY'), ('1b', 'MONEY')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "texts = [\n",
    "    \"Net income was $9.4 million compared to the prior year of $2.7 million.\",\n",
    "    \"Revenue exceeded twelve billion dollars, with a loss of $1b.\",\n",
    "]\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "for doc in nlp.pipe(texts, disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"]):\n",
    "    # Do something with the doc here\n",
    "    print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2734c34b-1b71-40e3-b8b9-3cfd53a3376e",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "\n",
    "Lemmatization is finding the lemma. It's the beginning of intent recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d9ad84b-4f09-4161-b1a4-348f2f0cafc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this this\n",
      "product product\n",
      "integrates integrate\n",
      "both both\n",
      "libraries library\n",
      "for for\n",
      "downloading download\n",
      "and and\n",
      "applying apply\n",
      "patches patch\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(u'this product integrates both libraries for downloading and applying patches')\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86da312d-fe41-4c37-ba94-16ac9bd5d301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['token:I lemma:I', 'token:am lemma:be', 'token:flying lemma:fly', 'token:to lemma:to', 'token:Frisco lemma:San Francisco']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# orth is simply an integer that indicates \n",
    "# the index of the occurrence of the word that \n",
    "# is kept in the spacy. tokens\n",
    "from spacy.symbols import LOWER, LEMMA\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "nlp.get_pipe(\"attribute_ruler\").add([[{\"LOWER\": \"frisco\"}]], {\"LEMMA\": \"San Francisco\"})\n",
    "\n",
    "doc = nlp(u'I am flying to Frisco')\n",
    "\n",
    "print(['token:%s lemma:%s' % (t.text, t.lemma_) for t in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e6e539-08c0-4542-99c4-5ec6e0369ae7",
   "metadata": {},
   "source": [
    "## Tagger\n",
    "\n",
    "PoS (Part of Speech) tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab87695f-9871-44b3-9654-983faee956c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token:I lemma:I pos:PRON tag:PRP\n",
      "token:have lemma:have pos:AUX tag:VBP\n",
      "token:flown lemma:fly pos:VERB tag:VBN\n",
      "token:to lemma:to pos:ADP tag:IN\n",
      "token:LA lemma:LA pos:PROPN tag:NNP\n",
      "token:. lemma:. pos:PUNCT tag:.\n",
      "token:Now lemma:now pos:ADV tag:RB\n",
      "token:I lemma:I pos:PRON tag:PRP\n",
      "token:am lemma:be pos:AUX tag:VBP\n",
      "token:flying lemma:fly pos:VERB tag:VBG\n",
      "token:to lemma:to pos:ADP tag:IN\n",
      "token:Frisco lemma:San Francisco pos:PROPN tag:NNP\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# orth is simply an integer that indicates \n",
    "# the index of the occurrence of the word that \n",
    "# is kept in the spacy. tokens\n",
    "from spacy.symbols import LOWER, LEMMA\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "nlp.get_pipe(\"attribute_ruler\").add([[{\"LOWER\": \"frisco\"}]], {\"LEMMA\": \"San Francisco\"})\n",
    "\n",
    "doc = nlp(u'I have flown to LA. Now I am flying to Frisco')\n",
    "\n",
    "for t in doc:\n",
    "    print('token:%s lemma:%s pos:%s tag:%s' % (t.text, t.lemma_, t.pos_, t.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6418a7bb-e35e-402a-82e2-4e8c291ae660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pronoun\n",
      "pronoun, personal\n",
      "auxiliary\n",
      "verb, non-3rd person singular present\n",
      "verb, past participle\n",
      "adposition\n",
      "conjunction, subordinating or preposition\n",
      "proper noun\n",
      "noun, proper singular\n",
      "punctuation\n",
      "adverb\n",
      "adverb\n",
      "verb\n",
      "verb, gerund or present participle\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "print(spacy.explain(\"PRON\"))\n",
    "print(spacy.explain(\"PRP\"))\n",
    "print(spacy.explain(\"AUX\"))\n",
    "print(spacy.explain(\"VBP\"))\n",
    "print(spacy.explain(\"VBN\"))\n",
    "print(spacy.explain(\"ADP\"))\n",
    "print(spacy.explain(\"IN\"))\n",
    "print(spacy.explain(\"PROPN\"))\n",
    "print(spacy.explain(\"NNP\"))\n",
    "print(spacy.explain(\"PUNCT\"))\n",
    "print(spacy.explain(\"ADV\"))\n",
    "print(spacy.explain(\"RB\"))\n",
    "print(spacy.explain(\"VERB\"))\n",
    "print(spacy.explain(\"VBG\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418e4502-9d14-4480-902a-c56d6380b2b3",
   "metadata": {},
   "source": [
    "## Dependepncy Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80499346-215f-4ab7-8a22-413c8bb4a322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token:I lemma:I pos:PRON tag:PRP\n",
      "token:have lemma:have pos:AUX tag:VBP\n",
      "token:flown lemma:fly pos:VERB tag:VBN\n",
      "token:to lemma:to pos:ADP tag:IN\n",
      "token:LA lemma:LA pos:PROPN tag:NNP\n",
      "token:. lemma:. pos:PUNCT tag:.\n",
      "token:Now lemma:now pos:ADV tag:RB\n",
      "token:I lemma:I pos:PRON tag:PRP\n",
      "token:am lemma:be pos:AUX tag:VBP\n",
      "token:flying lemma:fly pos:VERB tag:VBG\n",
      "token:to lemma:to pos:ADP tag:IN\n",
      "token:Frisco lemma:San Francisco pos:PROPN tag:NNP\n",
      "token:I lemma:I pos:PRON dep:nsubj\n",
      "token:have lemma:have pos:AUX dep:aux\n",
      "token:flown lemma:fly pos:VERB dep:ROOT\n",
      "token:to lemma:to pos:ADP dep:prep\n",
      "token:LA lemma:LA pos:PROPN dep:pobj\n",
      "token:. lemma:. pos:PUNCT dep:punct\n",
      "token:Now lemma:now pos:ADV dep:advmod\n",
      "token:I lemma:I pos:PRON dep:nsubj\n",
      "token:am lemma:be pos:AUX dep:aux\n",
      "token:flying lemma:fly pos:VERB dep:ROOT\n",
      "token:to lemma:to pos:ADP dep:prep\n",
      "token:Frisco lemma:San Francisco pos:PROPN dep:pobj\n",
      "token head text:flown dependency:nsubj text:I\n",
      "token head text:flown dependency:aux text:have\n",
      "token head text:flown dependency:ROOT text:flown\n",
      "token head text:flown dependency:prep text:to\n",
      "token head text:to dependency:pobj text:LA\n",
      "token head text:flown dependency:punct text:.\n",
      "token head text:flying dependency:advmod text:Now\n",
      "token head text:flying dependency:nsubj text:I\n",
      "token head text:flying dependency:aux text:am\n",
      "token head text:flying dependency:ROOT text:flying\n",
      "token head text:flying dependency:prep text:to\n",
      "token head text:to dependency:pobj text:Frisco\n",
      "['flown', 'LA']\n",
      "['flying', 'Frisco']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# orth is simply an integer that indicates \n",
    "# the index of the occurrence of the word that \n",
    "# is kept in the spacy. tokens\n",
    "from spacy.symbols import LOWER, LEMMA\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "nlp.get_pipe(\"attribute_ruler\").add([[{\"LOWER\": \"frisco\"}]], {\"LEMMA\": \"San Francisco\"})\n",
    "\n",
    "doc = nlp(u'I have flown to LA. Now I am flying to Frisco')\n",
    "\n",
    "for t in doc:\n",
    "    print('token:%s lemma:%s pos:%s tag:%s' % (t.text, t.lemma_, t.pos_, t.tag_))\n",
    "\n",
    "for t in doc:\n",
    "    print('token:%s lemma:%s pos:%s dep:%s' % (t.text, t.lemma_, t.pos_, t.dep_))\n",
    "\n",
    "for t in doc:\n",
    "    print('token head text:%s dependency:%s text:%s' % (t.head.text, t.dep_, t.text))\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print([w.text for w in sent if w.dep_ == 'ROOT' or w.dep_ == 'pobj'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d61a47-f621-425f-a947-d421a3c400b2",
   "metadata": {},
   "source": [
    "## NER (Named Entity Recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e94a40e8-d1e7-4283-ac98-2a7f091e5d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LA GPE\n",
      "San Francisco GPE\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# orth is simply an integer that indicates \n",
    "# the index of the occurrence of the word that \n",
    "# is kept in the spacy. tokens\n",
    "from spacy.symbols import LOWER, LEMMA\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "nlp.get_pipe(\"attribute_ruler\").add([[{\"LOWER\": \"frisco\"}]], {\"LEMMA\": \"San Francisco\"})\n",
    "\n",
    "doc = nlp(u'I have flown to LA. Now I am flying to Frisco')\n",
    "\n",
    "for token in doc:\n",
    "    if token.ent_type != 0:\n",
    "        print(token.lemma_, token.ent_type_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
